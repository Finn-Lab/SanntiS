{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52a2d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import sys\n",
    "import time\n",
    "\n",
    "tic = time.time()\n",
    "import logging as log\n",
    "from distutils.spawn import find_executable\n",
    "from itertools import groupby\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# from tensorflow.keras import models\n",
    "import tensorflow as tf\n",
    "\n",
    "# sys.path.append(os.path.dirname(os.path.abspath(__file__)))\n",
    "from joblib import load\n",
    "\n",
    "# from predictors.predictType import TypeClassification\n",
    "# from annotators import prodigal_annot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4367af45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    '_',\n",
    "    '--ip',\n",
    "    '/Users/fragoso/Downloads/ws/bench/files/comp/CM000950.fna.prodigal.faa.ip.tsv',\n",
    "    '--prodigal',\n",
    "    '/Users/fragoso/Downloads/ws/bench/files/comp/CM000950.fna.prodigal.faa',\n",
    "]\n",
    "__file__ = '/Users/fragoso/modules/old_emerald/emerald.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "562d0448",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "    \"\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4144661d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tmpDir:\n",
    "    \"\"\"Move to directory and back to original\"\"\"\n",
    "\n",
    "    def __init__(self, dire):\n",
    "        self.dir = dire\n",
    "        self.cwd = os.getcwd()\n",
    "\n",
    "    def __enter__(self):\n",
    "        os.makedirs(self.dir, exist_ok=True)\n",
    "        os.chdir(self.dir)\n",
    "        return self.dir\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb):\n",
    "        os.chdir(self.cwd)\n",
    "\n",
    "\n",
    "class Loss:\n",
    "    \"\"\"Load loss function used in trainings\"\"\"\n",
    "\n",
    "    def __init__(self, gamma):\n",
    "\n",
    "        self.gamma = gamma\n",
    "\n",
    "    @tf.function\n",
    "    def robustLoss(self, true, pred, sample_weight=None):\n",
    "        import tensorflow.keras.backend as k\n",
    "\n",
    "        \"\"\"Akiyama, ., Imoto, K., Tonami, N., Okamoto, Y., Yamanishi, R., Fukumori, T., & Yamashita, Y. (2020).  \n",
    "        Sound Event Detection Using Duration Robust Loss Function. arXiv preprint arXiv:2006.15253. \n",
    "        \"\"\"\n",
    "        error = (((2 - k.sigmoid(pred)) ** self.gamma) * k.log(k.sigmoid(pred))) + (\n",
    "            (k.sigmoid(pred) ** self.gamma) * (1 - true) * (k.log(1 - k.sigmoid(pred)))\n",
    "        )\n",
    "\n",
    "        if sample_weight == None:\n",
    "            return -k.sum(error, axis=0)\n",
    "        else:\n",
    "            return -k.sum(error * sample_weight, axis=0)\n",
    "\n",
    "\n",
    "class AnnotationFilesToEmerald:\n",
    "    \"\"\"Transform external tool's files into EMERALD STR\"\"\"\n",
    "\n",
    "    def __init__(self, shape=False):\n",
    "\n",
    "        self.entriesDct = {}\n",
    "        self.contigsDct = {}\n",
    "        self.annDct = {}\n",
    "        self.typeDct = {}\n",
    "        self.annResults = {}\n",
    "        self.gff3 = []\n",
    "        self.shape = shape\n",
    "\n",
    "    def transformIPS(self, ipsFile, f=\"TSV\"):\n",
    "\n",
    "        if not os.path.isfile(ipsFile):\n",
    "            log.exception(f\"{ipsFile} file not found\")\n",
    "\n",
    "        with open(ipsFile, \"r\") as h:\n",
    "\n",
    "            if f == \"GFF3\":\n",
    "\n",
    "                for l in h:\n",
    "\n",
    "                    if l[0] == \"#\":\n",
    "                        continue\n",
    "\n",
    "                    if \"protein_match\" in l:\n",
    "                        spl2 = l.split(\"\\t\")[-1][:-2]\n",
    "                        eDct = dict([x.split(\"=\") for x in spl2.split(\";\")])\n",
    "                        entry = (\n",
    "                            eDct[\"Dbxref\"].split(\":\")[-1][:-1]\n",
    "                            if \"Dbxref\" in eDct\n",
    "                            else eDct[\"Name\"]\n",
    "                        )\n",
    "                        self.entriesDct.setdefault(\n",
    "                            eDct[\"Target\"].split()[0], []\n",
    "                        ).append(entry)\n",
    "\n",
    "            elif f == \"TSV\":\n",
    "\n",
    "                for l in h:\n",
    "\n",
    "                    spl = l.split(\"\\t\")\n",
    "                    self.entriesDct.setdefault(spl[0], []).append(\n",
    "                        spl[11] if (len(spl) > 11 and spl[11][:2] == \"IP\") else spl[4]\n",
    "                    )\n",
    "            else:\n",
    "                log.exception(f\"Unrecognised IPS format\")\n",
    "\n",
    "    def transformEmeraldHmm(self, hmmFiles):\n",
    "\n",
    "        for hmmFile in hmmFiles:\n",
    "            log.info(f\"processing {hmmFile}\")\n",
    "            if not os.path.isfile(hmmFile):\n",
    "                log.exception(f\"{hmmFile} file not found\")\n",
    "\n",
    "            with open(hmmFile, \"r\") as h:\n",
    "\n",
    "                for l in h:\n",
    "\n",
    "                    if l[0] == \"#\":\n",
    "                        continue\n",
    "\n",
    "                    spl = l.split()\n",
    "                    self.entriesDct.setdefault(spl[3], []).append(spl[0])\n",
    "\n",
    "    def transformCDSpredToCDScontigs(self, cdsPredFile, f=\"FASTA\"):\n",
    "\n",
    "        if not os.path.isfile(cdsPredFile):\n",
    "            log.exception(f\"{cdsPredFile} file not found\")\n",
    "\n",
    "        with open(cdsPredFile, \"r\") as h:\n",
    "\n",
    "            if f == \"FASTA\":\n",
    "\n",
    "                for l in h:\n",
    "\n",
    "                    if l[0] != \">\":\n",
    "                        continue\n",
    "\n",
    "                    spl = l.split()\n",
    "                    start, end = int(spl[2]), int(spl[4])\n",
    "\n",
    "                    self.contigsDct.setdefault(\n",
    "                        \"_\".join(spl[0].split(\"_\")[:-1])[1:], []\n",
    "                    ).append((spl[0][1:], (start, end)))\n",
    "\n",
    "            elif f == \"GBK\":\n",
    "\n",
    "                from Bio import SeqIO\n",
    "\n",
    "                recs = list(SeqIO.parse(open(cdsPredFile, \"r\"), \"gb\"))\n",
    "\n",
    "                for rec in recs:\n",
    "                    for f in rec.features:\n",
    "                        if f.type == \"CDS\":\n",
    "\n",
    "                            start, end = int(f.location.start) + 1, int(f.location.end)\n",
    "\n",
    "                            self.contigsDct.setdefault(rec.id, []).append(\n",
    "                                (\n",
    "                                    f.qualifiers[\"protein_id\"]\n",
    "                                    if \"protein_id\" in f.qualifiers\n",
    "                                    else f.qualifiers[\"locus_tag\"],\n",
    "                                    (start, end),\n",
    "                                )\n",
    "                            )\n",
    "\n",
    "    def buildMatrices(self, annVocab):\n",
    "\n",
    "        log.info(\"Building matrices\")\n",
    "\n",
    "        for contig in self.contigsDct:\n",
    "\n",
    "            cdss = self.contigsDct[contig]\n",
    "\n",
    "            samps = (\n",
    "                len(cdss)\n",
    "                if not self.shape\n",
    "                else ((len(cdss) // self.shape) + 1) * self.shape\n",
    "            )\n",
    "            log.info(f\"self.samps {samps}\")\n",
    "\n",
    "            self.annDct[contig] = np.zeros((samps, len(annVocab)))\n",
    "            #             self.typeDct[contig] = np.zeros((samps, len(typeVocab)))\n",
    "\n",
    "            for ix, cds in enumerate(cdss):\n",
    "\n",
    "                name = cds[0]\n",
    "                if name not in self.entriesDct:\n",
    "                    continue\n",
    "\n",
    "                modiAnn = [annVocab[x] for x in self.entriesDct[name] if x in annVocab]\n",
    "                #                 modiType = [\n",
    "                #                     typeVocab[x] for x in self.entriesDct[name] if x in typeVocab\n",
    "                #                 ]\n",
    "                self.annDct[contig][ix][modiAnn] = 1\n",
    "\n",
    "    #                 self.typeDct[contig][ix][modiType] = 1\n",
    "\n",
    "    def predictAnn(self, model, colapseFunc=max):\n",
    "\n",
    "        log.info(\"Predict BGC probability w/ TensorFlow\")\n",
    "        for contig in self.annDct:\n",
    "            mat = self.annDct[contig]\n",
    "            xva_, vaIx = self.transformMat(mat)\n",
    "            vaS = (xva_.shape[0] // self.shape) * self.shape\n",
    "            xva1 = xva_[:vaS].reshape(vaS // self.shape, self.shape)\n",
    "            xva = np.append(\n",
    "                xva1,\n",
    "                [list(xva_[vaS:]) + [0] * (self.shape - (vaIx.shape[0] - vaS))],\n",
    "                axis=0,\n",
    "            )\n",
    "            self.predict_ = model.predict(xva)\n",
    "            predict = self.predict_.reshape(vaS + self.shape)\n",
    "            predict_str_, nix = self.partialReStrMat(vaIx, predict, func=colapseFunc)\n",
    "            self.annResults[contig] = self.projectRes(predict_str_, nix, mat.shape[0])\n",
    "\n",
    "    def transformMat(self, mat):\n",
    "\n",
    "        scuash = np.array(list(map(lambda x: np.where(x == 1)[0], mat)))\n",
    "        nli, nix = [], []\n",
    "        for ix, x in enumerate(scuash):\n",
    "            if x.shape[0] == 0:\n",
    "                continue\n",
    "            nli.extend(x)\n",
    "            nix.extend([ix] * x.shape[0])\n",
    "        sups = [\n",
    "            (k, list(zip(*g))[1][0])\n",
    "            for k, g in groupby(zip(nli, nix), key=lambda x: x[0])\n",
    "        ]\n",
    "        if len(nli) == 0:\n",
    "            return np.array([0]), np.array([0])\n",
    "        a, b = list(zip(*sups))\n",
    "        a, b = np.array(a), np.array(b)\n",
    "        return a, b\n",
    "\n",
    "    def projectRes(self, res, ixes, lenOri):\n",
    "\n",
    "        nres_ = np.zeros(lenOri)\n",
    "        nres_[ixes] = res\n",
    "        prev = 0\n",
    "        rprev = 0\n",
    "        for ix, r in zip(ixes, res):\n",
    "            if ix - 1 == prev:\n",
    "                prev = ix\n",
    "                rprev = r\n",
    "                continue\n",
    "            for ixx, s in list(enumerate(np.linspace(rprev, r, ix - prev + 1)))[1:-1]:\n",
    "                nres_[prev + ixx] = s\n",
    "            prev = ix\n",
    "\n",
    "        return nres_\n",
    "\n",
    "    def partialReStrMat(self, Ix, res, func):\n",
    "\n",
    "        nres, nix = [], []\n",
    "        for k, g in groupby(zip(res, Ix), key=lambda x: x[1]):\n",
    "\n",
    "            gg = list(list(zip(*g))[0])\n",
    "            nix.append(k)\n",
    "            nres.append(func(gg))\n",
    "        return np.array(nres), np.array(nix)\n",
    "\n",
    "    def defineLooseClusters(self, thBase=0.875, thBorder=0.9, rmless=3, fill=3):\n",
    "\n",
    "        log.info(\"Define Clusters\")\n",
    "        self.bridged, self.looseClst, self.borderClst, self.typesClst = {}, {}, {}, {}\n",
    "\n",
    "        for contig in self.annResults:\n",
    "            self.looseClst[contig] = np.array(\n",
    "                self.rmLessThan(\n",
    "                    self.fillGap(\n",
    "                        np.where(self.annResults[contig] < thBase, 0, 1), fill\n",
    "                    ),\n",
    "                    rmless,\n",
    "                )\n",
    "            )\n",
    "            self.borderClst[contig] = np.where(self.annResults[contig] < thBorder, 0, 1)\n",
    "            self.typesClst[contig] = np.zeros((len(self.annResults[contig]), 8))\n",
    "\n",
    "    def rmLessThan(self, contig, n):\n",
    "        newContig = []\n",
    "        for k, g in groupby(contig):\n",
    "            if k == 0:\n",
    "                newContig.extend(list(g))\n",
    "            else:\n",
    "                p = list(g)\n",
    "                if len(p) <= n:\n",
    "                    newContig.extend([0 for x in p])\n",
    "                else:\n",
    "                    newContig.extend(p)\n",
    "        return newContig\n",
    "\n",
    "    def fillGap(self, contig, gap):\n",
    "        newContig = []\n",
    "        for k, g in groupby(contig):\n",
    "            gg = list(g)\n",
    "            if k == 0 and len(gg) <= gap:\n",
    "                newContig.extend([1 for x in gg])\n",
    "            else:\n",
    "                newContig.extend(gg)\n",
    "        return newContig\n",
    "\n",
    "    def predictType(self, typeModel, allTh, posTh, g):\n",
    "\n",
    "        log.info(\"Predict BGC classes\")\n",
    "        greed = {0:0.58, 1: 0.41, 2: 0.345, 3: 0}\n",
    "\n",
    "        #         posTh = greed[g] if g != None else posTh\n",
    "        posTh = greed[g] if posTh == None else posTh\n",
    "        log.info(f\"Pos_class model Thres {posTh}\")\n",
    "        locations, matrix, typeLi = [], [], []\n",
    "        claa = [\n",
    "                    \"Alkaloid\",\n",
    "                    \"All\",\n",
    "                    \"NRP\",\n",
    "                    \"Polyketide\",\n",
    "                    \"RiPP\",\n",
    "                    \"Saccharide\",\n",
    "                    \"Terpene\",\n",
    "                    \"Other\",\n",
    "                ]\n",
    "\n",
    "        for contig in self.contigsDct:\n",
    "            for k, g in groupby(enumerate(self.looseClst[contig]), key=lambda x: x[1]):\n",
    "                if k == 0:\n",
    "                    continue\n",
    "                gg = list(list(zip(*g))[0])\n",
    "                tmat_ = np.sum(self.annDct[contig][gg], axis=0)\n",
    "                tmat = np.where(tmat_ > 0, 1, 0)\n",
    "                #                 typePrediction.setdefault(contig)\n",
    "                locations.append((contig, gg))\n",
    "                matrix.append(tmat)\n",
    "        if len(matrix) > 0:\n",
    "            pred = np.empty((len(matrix), len(claa)))\n",
    "            for nc, cla in enumerate( claa ):\n",
    "                pred[:, nc] = typeModel[cla].predict_proba(matrix)[:, 1]\n",
    "        else:\n",
    "            pred = []\n",
    "\n",
    "        for ix, p in enumerate(pred):\n",
    "\n",
    "            contig, gg = locations[ix]\n",
    "\n",
    "            if not (p[1] >= allTh and np.max(p[[0, 2, 3, 4, 5, 6, 7]]) >= posTh):\n",
    "            #if not (p[1] >= allTh and np.max(p[[0, 4, 5, 6]]) >= posTh) and not (p[1] >= allTh and np.max(p[[2, 3]]) >= posTh-0.07):\n",
    "                self.looseClst[contig][gg] = 0\n",
    "                self.borderClst[contig][gg] = 0\n",
    "\n",
    "            else:\n",
    "                log.info(str(p))\n",
    "                self.typesClst[contig][gg] = p\n",
    "\n",
    "    def writeGff3(self, outfile=\"emerald.full.gff\", emrldV=0.1):\n",
    "\n",
    "        log.info(\"build GFF3\")\n",
    "        log.info(outfile)\n",
    "        type_code = {\n",
    "            0: \"Alkaloid\",\n",
    "            1: \"All\",\n",
    "            2: \"NRP\",\n",
    "            3: \"Polyketide\",\n",
    "            4: \"RiPP\",\n",
    "            5: \"Saccharide\",\n",
    "            6: \"Terpene\",\n",
    "            7: \"Other\",\n",
    "        }\n",
    "\n",
    "        for contig in self.looseClst:\n",
    "\n",
    "            ### annot cds\n",
    "            for ix, f in enumerate(self.contigsDct[contig]):\n",
    "\n",
    "                ID, (start, end) = f\n",
    "                emrldProb = \"{:.3f}\".format(self.annResults[contig][ix])\n",
    "                self.gff3.append(\n",
    "                    f\"{contig}\\tEMERALDv{emrldV}\\tCDS\\t{start}\\t{end}\\t.\\t.\\t.\\tID={ID};emerald_probability={emrldProb}\"\n",
    "                )\n",
    "\n",
    "            ### annot clusters\n",
    "\n",
    "            ct = 1\n",
    "            for k, g in groupby(\n",
    "                enumerate(self.looseClst[contig][: len(self.contigsDct[contig])]),\n",
    "                key=lambda x: x[1],\n",
    "            ):\n",
    "\n",
    "                if k == 0:\n",
    "                    continue\n",
    "\n",
    "                ID = f\"{contig}_emrld_{ct}\"\n",
    "                ct += 1\n",
    "\n",
    "                gg = list(list(zip(*g))[0])\n",
    "\n",
    "                start, end = (\n",
    "                    self.contigsDct[contig][gg[0]][1][0],\n",
    "                    self.contigsDct[contig][gg[-1]][1][1],\n",
    "                )\n",
    "\n",
    "                ### asses if bgc in edge of contig\n",
    "                edge = (\n",
    "                    str(True)\n",
    "                    if (gg[0] == 0 or gg[-1] == len(self.contigsDct[contig]) - 1)\n",
    "                    else str(False)\n",
    "                )\n",
    "\n",
    "                tClst = self.typesClst[contig][gg[0]]\n",
    "                typs = \",\".join(\n",
    "                    [\n",
    "                        \"{}:{:.3f}\".format(type_code[ix], tClst[ix])\n",
    "                        for ix in [0, 2, 3, 4, 5, 6, 7]\n",
    "                    ]\n",
    "                )\n",
    "\n",
    "                self.gff3.append(\n",
    "                    f\"{contig}\\tEMERALDv{emrldV}\\tCLUSTER\\t{start}\\t{end}\\t.\\t.\\t.\\tID={ID};Class_Probability={typs};Edge={edge}\"\n",
    "                )\n",
    "\n",
    "                ct2 = 1\n",
    "                for k2, g2 in groupby(\n",
    "                    zip(gg, self.borderClst[contig][gg]), key=lambda x: x[1]\n",
    "                ):\n",
    "                    if k2 == 0:\n",
    "                        continue\n",
    "                    gg2 = list(list(zip(*g2))[0])\n",
    "                    start, end = (\n",
    "                        self.contigsDct[contig][gg2[0]][1][0],\n",
    "                        self.contigsDct[contig][gg2[-1]][1][1],\n",
    "                    )\n",
    "                    ### asses if bgc in edge of contig\n",
    "                    edge = (\n",
    "                        str(True)\n",
    "                        if (gg2[0] == 0 or gg2[-1] == len(self.contigsDct[contig]) - 1)\n",
    "                        else str(False)\n",
    "                    )\n",
    "\n",
    "                    self.gff3.append(\n",
    "                        f\"{contig}\\tEMERALDv{emrldV}\\tCLUSTER_border\\t{start}\\t{end}\\t.\\t.\\t.\\tID={ID}_{ct2};Class_Probability={typs};Edge={edge}\"\n",
    "                    )\n",
    "                    ct2 += 1\n",
    "\n",
    "        log.info(f\"Writing output to file {outfile}\")\n",
    "        with open(outfile, \"w\") as h:\n",
    "\n",
    "            h.write(\"##gff-version 3\\n\")\n",
    "\n",
    "            for l in sorted(\n",
    "                self.gff3,\n",
    "                key=lambda x: (\n",
    "                    x.split(\"\\t\")[0],\n",
    "                    int(x.split(\"\\t\")[3]),\n",
    "                    x.split(\"\\t\")[2],\n",
    "                ),\n",
    "            ):\n",
    "\n",
    "                h.write(f\"{l}\\n\")\n",
    "\n",
    "\n",
    "class Preprocess:\n",
    "    \"\"\"External tools needed for emerald bgc detection\"\"\"\n",
    "\n",
    "    def __init__(self, cpus, outdir=None):\n",
    "\n",
    "        self.cpus = int(cpus)\n",
    "        self.outdir = outdir if outdir else \"temp\"\n",
    "\n",
    "    def runProdigal(self, fna, meta=False):\n",
    "        \"\"\"Predict genes using prodigal\"\"\"\n",
    "        log.info(\"Progial gene prediction...\")\n",
    "\n",
    "        if not find_executable(\"prodigal\"):\n",
    "            log.exception(\"Parodigal is not installed or in PATH\")\n",
    "\n",
    "        if not os.path.isfile(fna):\n",
    "            log.exception(f\"{fna} file not found\")\n",
    "\n",
    "        outFaa = \"{}.prodigal.faa\".format(os.path.basename(fna))\n",
    "        log.info(f\"{fna} {outFaa}\")\n",
    "        cmd = [\"prodigal\", \"-i\", fna, \"-a\", outFaa] + ([\"-p\", \"meta\"] if meta else [])\n",
    "\n",
    "        with tmpDir(self.outdir):\n",
    "            #             try:\n",
    "            outs, errs = subprocess.Popen(\n",
    "                cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "            ).communicate()\n",
    "            if \"Error:  Sequence must be 20000 characters\" in errs.decode(\"utf8\"):\n",
    "\n",
    "                log.info(\n",
    "                    \"Sequence must be 20000 characters when running Prodigal in normal mode. Trying -p meta\"\n",
    "                )\n",
    "\n",
    "                cmd = [\"prodigal\", \"-i\", fna, \"-a\", outFaa] + ([\"-p\", \"meta\"])\n",
    "\n",
    "                outs, errs = subprocess.Popen(\n",
    "                    cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "                ).communicate()\n",
    "\n",
    "            #                 log.info(outs)\n",
    "            log.info(errs.decode(\"utf8\"))\n",
    "            #                 log.info(\"Prodigal succesful\")\n",
    "            #             except subprocess.CalledProcessError as err:\n",
    "            #                 print(\"Failed\")\n",
    "            #                 log.exception(err.output)\n",
    "\n",
    "            \"\"\" Remove asterixs from faa\n",
    "                \"\"\"\n",
    "            log.info(\"Removing asterix from prodigal faa\")\n",
    "            with open(outFaa, \"r\") as h:\n",
    "                noAstFaa = [x.replace(\"*\", \"\") for x in h]\n",
    "            with open(outFaa, \"w\") as h:\n",
    "                for l in noAstFaa:\n",
    "                    h.write(f\"{l}\")\n",
    "\n",
    "            return os.path.abspath(outFaa)\n",
    "\n",
    "    def gbkToProdigal(self, gbk):\n",
    "        \"\"\"Transform gbk to faa. This enables preprocessing with sequences\"\"\"\n",
    "        log.info(\"write gbk as faa\")\n",
    "        from Bio import SeqIO\n",
    "\n",
    "        recs = list(SeqIO.parse(open(gbk, \"r\"), \"gb\"))\n",
    "\n",
    "        base = os.path.basename(gbk)\n",
    "\n",
    "        with tmpDir(self.outdir):\n",
    "\n",
    "            with open(f\"{base}.faa\", \"w\") as h:\n",
    "\n",
    "                for rec in recs:\n",
    "\n",
    "                    for f in rec.features:\n",
    "\n",
    "                        if f.type == \"CDS\" and \"translation\" in f.qualifiers:\n",
    "\n",
    "                            pid = (\n",
    "                                f.qualifiers[\"protein_id\"]\n",
    "                                if \"protein_id\" in f.qualifiers\n",
    "                                else f.qualifiers[\"locus_tag\"]\n",
    "                            )\n",
    "                            seq = f.qualifiers[\"translation\"][0]\n",
    "                            h.write(f\">{pid}\\n{seq}\\n\")\n",
    "\n",
    "            return os.path.abspath(f\"{base}.emerald.faa\")\n",
    "\n",
    "    def runHmmScan(self, faa, hmmLib):\n",
    "        \"\"\"annotate functionally with emerald hmm library and hmmScan\"\"\"\n",
    "        log.info(\"emerald functional annotation...\")\n",
    "\n",
    "        if not find_executable(\"hmmscan\"):\n",
    "            log.exception(\"hmmscan is not installed or in PATH\")\n",
    "\n",
    "        if not os.path.isfile(faa):\n",
    "            log.exception(f\"{faa} file not found\")\n",
    "\n",
    "        if not os.path.isfile(hmmLib):\n",
    "            log.exception(f\"{hmmLib} file not found\")\n",
    "\n",
    "        outTsv = \"{}.emerald.tsv\".format(os.path.basename(faa))\n",
    "\n",
    "        cmd = (\n",
    "            [\"hmmscan\", \"--domtblout\", outTsv, \"--cut_ga\"]\n",
    "            + ([\"--cpu\", str(self.cpus)] if self.cpus else [])\n",
    "            + ([hmmLib, faa])\n",
    "        )\n",
    "        log.info(cmd)\n",
    "        with tmpDir(self.outdir):\n",
    "            try:\n",
    "                #                 subprocess.check_call(\n",
    "                outs, errs = subprocess.Popen(\n",
    "                    cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "                ).communicate()\n",
    "                log.info(errs.decode(\"utf8\"))\n",
    "            #                 log.info(outs)\n",
    "            #                 log.info(\"emerald annotation succesful\")\n",
    "            except subprocess.CalledProcessError as err:\n",
    "                log.exception(err.output)\n",
    "\n",
    "            return os.path.abspath(outTsv)\n",
    "\n",
    "    def runInterproscan(\n",
    "        self,\n",
    "        faa,\n",
    "        analyses=[\"Pfam\", \"TIGRFAM\", \"PRINTS\", \"ProSitePatterns\", \"Gene3D\"],\n",
    "    ):\n",
    "        \"\"\"annotate functionally with InterproScan\"\"\"\n",
    "        log.info(\n",
    "            \"InterProScan functional annotation... version 83 is user responsability\"\n",
    "        )\n",
    "\n",
    "        if not find_executable(\"interproscan.sh\"):\n",
    "            log.exception(\"interproscan.sh is not installed or in PATH\")\n",
    "\n",
    "        if not os.path.isfile(faa):\n",
    "            log.exception(f\"{faa} file not found\")\n",
    "\n",
    "        outGff = \"{}.ip.tsv\".format(os.path.basename(faa))\n",
    "        cmd = (\n",
    "            [\"interproscan.sh\", \"-i\", faa, \"-o\", outGff, \"-f\", \"TSV\"]\n",
    "            + ([\"-appl\", \",\".join(analyses)] if analyses else [])\n",
    "            + ([\"-cpu\", str(self.cpus)] if self.cpus else [])\n",
    "        )\n",
    "        log.info(\" \".join(cmd))\n",
    "\n",
    "        with tmpDir(self.outdir):\n",
    "            #             try:\n",
    "            outs, errs = subprocess.Popen(\n",
    "                cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE\n",
    "            ).communicate()\n",
    "            log.info(outs.decode(\"utf8\"))\n",
    "            log.info(errs.decode(\"utf8\"))\n",
    "            #                 log.info(\"Prodigal succesful\")\n",
    "            #             except subprocess.CalledProcessError as err:\n",
    "            #                 log.exception(err.output)\n",
    "\n",
    "            return os.path.abspath(outGff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0f9282",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(\n",
    "    description=\"EMERALD. detect SM Biosynthetic Gene Clusters\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--fna\",\n",
    "    dest=\"fna\",\n",
    "    type=str,\n",
    "    default=False,\n",
    "    help=\"nucleotide sequnce file, this option overrides -gbk, -ip,-ih\",\n",
    "    metavar=\"FILE\",\n",
    ")\n",
    "# parser.add_argument( \"--prod\", dest=\"prodigal\",\n",
    "#                  help=\"prodigal translation sequnce file\", metavar=\"FILE\")\n",
    "parser.add_argument(\n",
    "    \"--gbk\",\n",
    "    dest=\"gbk\",\n",
    "    type=str,\n",
    "    default=False,\n",
    "    help=\"protein annotated genebank file\",\n",
    "    metavar=\"FILE\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--prodigal\",\n",
    "    dest=\"prodigal\",\n",
    "    type=str,\n",
    "    help=\"tranlations from prodigal file\",\n",
    "    metavar=\"FILE\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ip\", dest=\"interpro\", type=str, help=\"InterProScan v83 file\", metavar=\"FILE\"\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ipf\",\n",
    "    dest=\"interpro_f\",\n",
    "    type=str,\n",
    "    help=\"InterProScan file format. TSV,GFF3... GFF3 not supported\",\n",
    "    default=\"TSV\",\n",
    "    metavar=\"FILE\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--ih\",\n",
    "    dest=\"inhouse\",\n",
    "    type=str,\n",
    "    help=\"inHouse TSV file\",\n",
    "    metavar=\"FILE\",\n",
    "    nargs=\"+\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--thres\",\n",
    "    dest=\"thBase\",\n",
    "    default=0.87333,\n",
    "    type=float,\n",
    "    help=\"BGC probability threshold\",\n",
    "    metavar=\"FLOAT\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--thBorder\",\n",
    "    dest=\"thBorder\",\n",
    "    default=0.98,\n",
    "    type=float,\n",
    "    help=\"BGC border refinement threshold\",\n",
    "    metavar=\"FLOAT\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--thPos\",\n",
    "    dest=\"posTh\",\n",
    "    default=None,\n",
    "    type=float,\n",
    "    help=\"postProcess negative filter threshold\",\n",
    "    metavar=\"FLOAT\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--thFilter\",\n",
    "    dest=\"thFilter\",\n",
    "    default=0,\n",
    "    type=float,\n",
    "    help=\"postProcess negative filter threshold\",\n",
    "    metavar=\"FLOAT\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--greed\",\n",
    "    dest=\"greed\",\n",
    "    default=2,\n",
    "    type=int,\n",
    "    help=\"Level of greediness. 0,1,2,3\",\n",
    "    metavar=\"INT\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--meta\",\n",
    "    dest=\"meta\",\n",
    "    default=False,\n",
    "    type=bool,\n",
    "    help=\"prodigal option meta [default False]\",\n",
    "    metavar=\"BOOL\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--outdir\",\n",
    "    dest=\"outdir\",\n",
    "    type=str,\n",
    "    help=\"output directory. default $PWD\",\n",
    "    metavar=\"DIRECTORY\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--outfile\",\n",
    "    dest=\"outfile\",\n",
    "    type=str,\n",
    "    help=\"output file, overrides --outdir\",\n",
    "    metavar=\"DIRECTORY\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--cpu\",\n",
    "    dest=\"cpu\",\n",
    "    default=1,\n",
    "    type=int,\n",
    "    help=\"cpus for INTERPROSCAN and HMMSCAN\",\n",
    "    metavar=\"INT\",\n",
    ")\n",
    "#     parser.add_argument(\n",
    "#         \"--clasModFiles\",\n",
    "#         dest=\"clasModFiles\",\n",
    "#         type=str,\n",
    "#         help=\"altenative ann model\",\n",
    "#         metavar=\"STR\",\n",
    "#     )\n",
    "parser.add_argument(\n",
    "    \"--clasModFiles\",\n",
    "    dest=\"clasModFiles\",\n",
    "    type=str,\n",
    "    help=\"alternative class models\",\n",
    "    metavar=\"FILE\",\n",
    "    nargs=\"+\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--model\",\n",
    "    dest=\"model\",\n",
    "    type=str,\n",
    "    help=\"altenative ann model\",\n",
    "    metavar=\"STR\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--vocab\",\n",
    "    dest=\"vocab\",\n",
    "    type=str,\n",
    "    help=\"alternative ann vocab\",\n",
    "    metavar=\"STR\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--shape\",\n",
    "    dest=\"shape\",\n",
    "    type=int,\n",
    "    default=200,\n",
    "    help=\"window size for altenative ann model\",\n",
    "    metavar=\"INT\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--rmless\",\n",
    "    dest=\"rmless\",\n",
    "    type=int,\n",
    "    default=1,\n",
    "    help=\"minimum bgc length\",\n",
    "    metavar=\"INT\",\n",
    ")\n",
    "parser.add_argument(\n",
    "    \"--fill\",\n",
    "    dest=\"fill\",\n",
    "    type=int,\n",
    "    default=3,\n",
    "    help=\"fill gap between dtected regions\",\n",
    "    metavar=\"INT\",\n",
    ")\n",
    "\n",
    "args = parser.parse_args()\n",
    "#     return args\n",
    "basef = (\n",
    "    args.gbk\n",
    "    if args.gbk\n",
    "    else args.fna\n",
    "    if args.fna\n",
    "    else args.prodigal\n",
    "    if args.prodigal\n",
    "    else None\n",
    ")\n",
    "base = os.path.basename(basef)\n",
    "\n",
    "outdir = (\n",
    "    os.path.abspath(args.outdir) if args.outdir else os.path.join(os.getcwd(), f'{base}.emrld')\n",
    "    )\n",
    "with tmpDir(outdir):\n",
    "    log.basicConfig(\n",
    "        filename=f\"{outdir}/emerald.log\",\n",
    "        level=log.DEBUG,\n",
    "        format=\"%(asctime)s %(message)s\",\n",
    "    )\n",
    "    print(f\"LOG_FILE: {outdir}/emerald.log\")\n",
    "    log.info(\"************     *******************\\n   EMRELAD...\\n  ************\")\n",
    "    log.info(f\"outdir: {outdir}\")\n",
    "\n",
    "log.info(\"loading models\")\n",
    "hmmlib = os.path.join(\n",
    "    os.path.dirname(os.path.abspath(__file__)), \"models\", \"emerald.hmm\"\n",
    ")\n",
    "model_BGC_file = os.path.join(\n",
    "    os.path.dirname(os.path.abspath(__file__)),\n",
    "    \"models\",\n",
    "    \"emerald.h5\" if not args.model else args.model,\n",
    ")\n",
    "log.info(f\"model file: {model_BGC_file}\")\n",
    "model_class_files = os.path.join(\n",
    "    os.path.dirname(os.path.abspath(__file__)), \"models\", \"*.rf.clf.joblib\"\n",
    ")  # if not args.clasModFiles else args.clasModFiles\n",
    "annVocab_file = os.path.join(\n",
    "    os.path.dirname(os.path.abspath(__file__)),\n",
    "    \"models\",\n",
    "    \"vocab.json\" if not args.vocab else args.vocab,\n",
    ")\n",
    "#     typeVocab_file = os.path.join(\n",
    "#         os.path.dirname(os.path.abspath(__file__)), \"models\", \"typeVocab.json\"\n",
    "#     )\n",
    "\n",
    "with open(annVocab_file, \"r\") as h:\n",
    "    annVocab = json.load(h)\n",
    "\n",
    "#     with open(typeVocab_file, \"r\") as h:\n",
    "#         typeVocab = json.load(h)\n",
    "clfClass = {}\n",
    "for f in (\n",
    "    glob.glob(model_class_files) if not args.clasModFiles else args.clasModFiles\n",
    "):\n",
    "    cla = os.path.basename(f).split(\".\")[0]\n",
    "    clfClass[cla] = load(f)\n",
    "\n",
    "rlf = Loss(None)\n",
    "annModel = tf.keras.models.load_model(\n",
    "    model_BGC_file, custom_objects={\"robustLoss\": rlf.robustLoss}\n",
    ")\n",
    "\n",
    "log.info(\"preprocessing files\")\n",
    "preprocess = Preprocess(cpus=args.cpu, outdir=outdir)\n",
    "\n",
    "log.info(\"asses input format\")\n",
    "if args.gbk:\n",
    "    log.info(\"process gbk file\")\n",
    "    prodigal_file = preprocess.gbkToProdigal(os.path.abspath(args.gbk))\n",
    "    cds_f = \"GBK\"\n",
    "\n",
    "elif args.fna or args.prodigal:\n",
    "    log.info(\"get prodigal file\")\n",
    "    prodigal_file = (\n",
    "        preprocess.runProdigal(os.path.abspath(args.fna), meta=args.meta)\n",
    "        if args.fna\n",
    "        else args.prodigal\n",
    "        if args.prodigal\n",
    "        else None\n",
    "    )\n",
    "    cds_f = \"FASTA\"\n",
    "#         file = args.fna if args.fna else args.prodigal\n",
    "\n",
    "else:\n",
    "    log.critical(\"No input file provides. --fna,--gbk,--prodigal. check -help\")\n",
    "\n",
    "log.info(\"get inhouse hmm file\")\n",
    "hmm_files = (\n",
    "    args.inhouse\n",
    "    if args.inhouse\n",
    "    else [preprocess.runHmmScan(prodigal_file, hmmlib)]\n",
    "    if prodigal_file\n",
    "    else None\n",
    ")\n",
    "\n",
    "log.info(\"get interproscan file\")\n",
    "ips_format, ips_file = (\n",
    "    (args.interpro_f, args.interpro)\n",
    "    if (args.interpro_f and args.interpro)\n",
    "    else (\"TSV\", preprocess.runInterproscan(prodigal_file))\n",
    "    if prodigal_file\n",
    "    else None\n",
    ")\n",
    "\n",
    "log.info(\"EMERALD process\")\n",
    "annotate = AnnotationFilesToEmerald(shape=args.shape)\n",
    "\n",
    "log.info(\"transform interpro file\")\n",
    "annotate.transformIPS(ips_file, f=ips_format)\n",
    "\n",
    "log.info(\"transform inhouse hmm file\")\n",
    "annotate.transformEmeraldHmm(hmm_files)\n",
    "\n",
    "log.info(\"transform cds file\")\n",
    "annotate.transformCDSpredToCDScontigs(prodigal_file, f=cds_f)\n",
    "\n",
    "log.info(\"transform dicts to np matrices\")\n",
    "annotate.buildMatrices(annVocab)\n",
    "\n",
    "log.info(\"predict bgc regions\")\n",
    "annotate.predictAnn(annModel)\n",
    "\n",
    "log.info(\"define clusters\")\n",
    "annotate.defineLooseClusters(\n",
    "    thBase=args.thBase, thBorder=args.thBorder, rmless=args.rmless, fill=args.fill\n",
    ")\n",
    "\n",
    "log.info(\"post-processing filters and type classification\")\n",
    "annotate.predictType(clfClass, allTh=args.thFilter, posTh=args.posTh, g=args.greed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3d447d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EMERALD succesful\n"
     ]
    }
   ],
   "source": [
    "log.info(\"write gff file\")\n",
    "annotate.writeGff3(\n",
    "    outfile=args.outfile if args.outfile else f\"{outdir}/{base}.emerald.full.gff2\",\n",
    "    emrldV=0.1,\n",
    ")\n",
    "\n",
    "# log.info(\"EMERALD succesful\")\n",
    "# run_time = tic - time.time()\n",
    "# log.info(f\"RUNNING TIME: {run_time}\")\n",
    "print(\"EMERALD succesful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53ec58d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/fragoso/modules/emeraldbgc/emeraldbgc/modules/CM000950.fna.prodigal.faa.emrld/CM000950.fna.prodigal.faa.emerald.full.gff2'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{outdir}/{base}.emerald.full.gff2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0cfc0315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CM000950\tEMERALDv0.1\tCLUSTER\t235657\t280316\t.\t.\t.\tID=CM000950_emrld_1;Class_Probability=Alkaloid:0.020,NRP:0.080,Polyketide:0.400,RiPP:0.070,Saccharide:0.120,Terpene:0.210,Other:0.240;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t651667\t716832\t.\t.\t.\tID=CM000950_emrld_2;Class_Probability=Alkaloid:0.410,NRP:0.880,Polyketide:0.720,RiPP:0.490,Saccharide:0.450,Terpene:0.270,Other:0.570;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t747262\t777103\t.\t.\t.\tID=CM000950_emrld_3;Class_Probability=Alkaloid:0.030,NRP:0.050,Polyketide:0.050,RiPP:0.030,Saccharide:0.260,Terpene:0.440,Other:0.120;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t917061\t974020\t.\t.\t.\tID=CM000950_emrld_4;Class_Probability=Alkaloid:0.070,NRP:0.110,Polyketide:0.200,RiPP:0.420,Saccharide:0.050,Terpene:0.020,Other:0.170;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t1451219\t1472608\t.\t.\t.\tID=CM000950_emrld_5;Class_Probability=Alkaloid:0.000,NRP:0.010,Polyketide:0.000,RiPP:0.400,Saccharide:0.000,Terpene:0.000,Other:0.020;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t1783748\t1853946\t.\t.\t.\tID=CM000950_emrld_6;Class_Probability=Alkaloid:0.190,NRP:0.510,Polyketide:0.840,RiPP:0.500,Saccharide:0.470,Terpene:0.160,Other:0.500;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t1894864\t1953271\t.\t.\t.\tID=CM000950_emrld_7;Class_Probability=Alkaloid:0.060,NRP:0.040,Polyketide:0.070,RiPP:0.040,Saccharide:0.410,Terpene:0.430,Other:0.160;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t2037759\t2065499\t.\t.\t.\tID=CM000950_emrld_8;Class_Probability=Alkaloid:0.000,NRP:0.200,Polyketide:0.060,RiPP:0.040,Saccharide:0.010,Terpene:0.000,Other:0.490;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t2423846\t2434683\t.\t.\t.\tID=CM000950_emrld_9;Class_Probability=Alkaloid:0.000,NRP:0.010,Polyketide:0.010,RiPP:0.740,Saccharide:0.010,Terpene:0.080,Other:0.030;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t2974377\t2994307\t.\t.\t.\tID=CM000950_emrld_10;Class_Probability=Alkaloid:0.110,NRP:0.020,Polyketide:0.090,RiPP:0.040,Saccharide:0.060,Terpene:0.280,Other:0.610;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t3638063\t3681381\t.\t.\t.\tID=CM000950_emrld_11;Class_Probability=Alkaloid:0.120,NRP:0.630,Polyketide:0.840,RiPP:0.020,Saccharide:0.300,Terpene:0.320,Other:0.640;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t3823745\t3855691\t.\t.\t.\tID=CM000950_emrld_12;Class_Probability=Alkaloid:0.000,NRP:0.110,Polyketide:0.050,RiPP:0.030,Saccharide:0.020,Terpene:0.000,Other:0.380;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t3969841\t3986931\t.\t.\t.\tID=CM000950_emrld_13;Class_Probability=Alkaloid:0.050,NRP:0.060,Polyketide:0.070,RiPP:0.650,Saccharide:0.030,Terpene:0.000,Other:0.090;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t4546490\t4579641\t.\t.\t.\tID=CM000950_emrld_14;Class_Probability=Alkaloid:0.090,NRP:0.250,Polyketide:0.360,RiPP:0.040,Saccharide:0.080,Terpene:0.180,Other:0.400;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t4754043\t4780527\t.\t.\t.\tID=CM000950_emrld_15;Class_Probability=Alkaloid:0.100,NRP:0.010,Polyketide:0.090,RiPP:0.070,Saccharide:0.070,Terpene:0.200,Other:0.360;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t5129720\t5146039\t.\t.\t.\tID=CM000950_emrld_16;Class_Probability=Alkaloid:0.050,NRP:0.320,Polyketide:0.080,RiPP:0.110,Saccharide:0.000,Terpene:0.000,Other:0.660;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t5271093\t5273041\t.\t.\t.\tID=CM000950_emrld_17;Class_Probability=Alkaloid:0.000,NRP:0.000,Polyketide:0.010,RiPP:0.165,Saccharide:0.000,Terpene:0.970,Other:0.130;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t5341020\t5364603\t.\t.\t.\tID=CM000950_emrld_18;Class_Probability=Alkaloid:0.030,NRP:0.020,Polyketide:0.140,RiPP:0.000,Saccharide:0.580,Terpene:0.000,Other:0.010;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t5464903\t5476144\t.\t.\t.\tID=CM000950_emrld_19;Class_Probability=Alkaloid:0.000,NRP:0.000,Polyketide:0.000,RiPP:0.551,Saccharide:0.000,Terpene:0.000,Other:0.000;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t5516963\t5527531\t.\t.\t.\tID=CM000950_emrld_20;Class_Probability=Alkaloid:0.000,NRP:0.460,Polyketide:0.730,RiPP:0.002,Saccharide:0.120,Terpene:0.240,Other:0.420;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t6164083\t6192894\t.\t.\t.\tID=CM000950_emrld_21;Class_Probability=Alkaloid:0.270,NRP:0.700,Polyketide:0.470,RiPP:0.010,Saccharide:0.200,Terpene:0.220,Other:0.710;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t6537370\t6557814\t.\t.\t.\tID=CM000950_emrld_22;Class_Probability=Alkaloid:0.060,NRP:0.010,Polyketide:0.100,RiPP:0.030,Saccharide:0.090,Terpene:0.010,Other:0.450;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t6792113\t6832578\t.\t.\t.\tID=CM000950_emrld_23;Class_Probability=Alkaloid:0.130,NRP:0.040,Polyketide:0.210,RiPP:0.140,Saccharide:0.060,Terpene:0.150,Other:0.370;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t7526991\t7555965\t.\t.\t.\tID=CM000950_emrld_24;Class_Probability=Alkaloid:0.140,NRP:0.110,Polyketide:0.090,RiPP:0.080,Saccharide:0.020,Terpene:0.320,Other:0.470;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t7693037\t7865528\t.\t.\t.\tID=CM000950_emrld_25;Class_Probability=Alkaloid:0.480,NRP:0.840,Polyketide:0.960,RiPP:0.140,Saccharide:0.810,Terpene:0.340,Other:0.640;Edge=False\n",
      "CM000950\tEMERALDv0.1\tCLUSTER\t7873080\t8025920\t.\t.\t.\tID=CM000950_emrld_26;Class_Probability=Alkaloid:0.460,NRP:0.920,Polyketide:0.880,RiPP:0.110,Saccharide:0.660,Terpene:0.410,Other:0.650;Edge=False\n"
     ]
    }
   ],
   "source": [
    "!grep \"TER\\s\" /Users/fragoso/modules/emeraldbgc/emeraldbgc/modules/CM000950.fna.prodigal.faa.emrld/CM000950.fna.prodigal.faa.emerald.full.gff2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055d54f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2baad84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218 250\n",
      "587 629\n",
      "657 684\n",
      "810 867\n",
      "1280 1297\n",
      "1553 1605\n",
      "1643 1690\n",
      "1757 1777\n",
      "2081 2086\n",
      "2552 2570\n",
      "3169 3198\n",
      "3316 3345\n",
      "3453 3469\n",
      "3962 3990\n",
      "4139 4161\n",
      "4439 4452\n",
      "4537 4538\n",
      "4594 4608\n",
      "4702 4712\n",
      "4745 4755\n",
      "5315 5340\n",
      "5655 5672\n",
      "5884 5926\n",
      "6527 6548\n",
      "6672 6791\n",
      "6800 6918\n"
     ]
    }
   ],
   "source": [
    "c = 'CM000950'\n",
    "\n",
    "for k,g in groupby(enumerate(annotate.looseClst[c]),key = lambda z:z[1]):\n",
    "    if k ==0:\n",
    "        continue\n",
    "    gg = list(zip(*g))\n",
    "    print(gg[0][0],gg[0][-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
